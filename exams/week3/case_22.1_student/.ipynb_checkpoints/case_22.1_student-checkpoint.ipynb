{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequently record weather data in your EC2 instance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "In this case, you will learn how to set up an automation script in the cloud. You will use Amazon's Elastic Compute Cloud (```EC2```) to automatically retrieve weather data via an application programming interface (```API```).\n",
    "\n",
    "Throughout the case study, you will configure and utilize a cloud resource meant for computational tasks. You should become familiar with the different basic options and capabilities specific to AWS while also getting acustomed to working on a remote machine through your terminal ```SSH```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Context.** You are an independent consultant working for multiple clients. One of your clients specializes in environmental research and they have approached you with a new requirement. They would like to keep track of the weather of New York and record how it changes over a period of time. They would like your help on fetching the weather data every hour from an API and storing that in an EC2 instance. Along with storing the weather data, they would also like you to generate certain plots and store them in the EC2 machine as well.\n",
    "\n",
    "**Business Problem.** Your task is to write Python scripts that would fetch the weather data from API, parse the data and store it in CSV files in the same instance. You would also generate certain plots as mentioned below and store that as well in the same instance.\n",
    "\n",
    "**Analytical Context.** The client wants you to fetch the data from [OpenWeatherMap API](https://openweathermap.org/api). You would be registering to this service, and using the API Key from the website to pull out the weather data every hour. The steps to be followed are:\n",
    "\n",
    "- Register on the Open Weather Map website and receive the API Key\n",
    "- Write a Python script that fetches the weather data and stores it in a json file\n",
    "- Write another Python script that reads the stored json file, parses it and stores it as a CSV file. The following steps need to be done for parsing:\n",
    "    - The datetime options are returned in timestamp format. That has to be converted to a proper human readable format.\n",
    "- After the CSV file is stored, provide the following:\n",
    "    - The minimum and maximum temperature in the next 48 hours\n",
    "    - A line graph of how the temperature would change in the next 48 hours\n",
    "    - A line graph of how the wind speed will change across 48 hours\n",
    "- Once the Python scripts are done, create a bash script that calls these functions.\n",
    "- Setup a cron job on the machine to execute every hour. The cron job should call the bash script, which will in turn call these 2 Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching an EC2 instance on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Amazon EC2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual servers offered as a web-service that are highly configurable, scalable, and accessible via a point-and-click management console on AWS. Amazon has eliminated much of the heavy lifting traditionally required to set up the hardware, software, memory, networking, permissions, storage, security, etc. needed for dedicated computation while maintaining an abundant set of configuration options allowing you to tailor your server to your specific needs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use EC2 as a Data Scientist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For computationally expensive tasks that your personal machine cannot handle\n",
    "- For time consuming tasks you want to run in parallel without sacrificing performance on your personal machine\n",
    "- For repetitive tasks that need to run automatically -- based on time, constraints, or external signals from other web-services or systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the configuration options?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many to fully explore each in detail as part of this case but as we walk through setting up and connecting to an instance we will touch upon the major categories of options available and provide resources for further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK. Let’s set one up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start by signing in to [AWS](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fnc2%3Dh_ct%26src%3Dheader-signin%26state%3DhashArgs%2523%26isauthcode%3Dtrue&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&forceMobileApp=0) using your root user credentials. If you have not created your own AWS account, please consult with your TA to obtain the relevant instructions or see precase_22.1 for instructions on signing up for your own AWS account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Navigate to the EC2 Management Console (Services > Compute > EC2).  \n",
    "![Step 1](aws_ec2_img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scroll down and click the “Launch Instance” button.  \n",
    "![Step 2](aws_ec2_img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You are now shown a wizard that will walk you through the major categories of options required to configure your instance. To begin, we must choose an Amazon Machine Image (AMI). This is essentially a template that describes the operating system, application server, and any additional software packages we want pre-installed on our virtual server. There are many AMI’s, some created and supported by Amazon, others by community users, and many that have been optimized for specific purposes so we urge you to read the descriptions of each. For the sake of this case, we will choose **Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type**\n",
    "![Step 4](aws_ec2_img3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Next, we are asked to specify the instance type. There is a wide selection of types which vary in CPU size, memory, storage, and networking capacity and are broadly organized into four families: Storage optimized, Memory optimized, Compute optimized, or General Purpose. For now we’re going to choose the ```t2.micro``` General Purpose instance which is **free tier eligible**.  \n",
    "![Step 6](aws_ec2_img4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. For further configuration, you can explore steps 3-7 but for now let’s accept the default configuration and click the “Review and Launch” button followed by “Launch”. Keep in mind that launching any services or using certain configuration options not explicitly labelled as  Free tier eligible  will result in charges on your account.  \n",
    "![Step 6](aws_ec2_img5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Select “Create a new key pair”, name it, download it, and then Launch the instance.  \n",
    "![Step 7](aws_ec2_img6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. While the instance is launching, we need to set the permission to the .pem file to be 400 for SSH to work. Ignore this if you are using Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "chmod 400 <path to .pem file>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Now lets connect to your freshly launched instance using SSH and the key pair you just downloaded by following steps outlined [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html). For Windows machines, you will need PuTTY installed and then will need to follow [these](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html) steps. PuTTY is a Windows tool used thats acts as an ```ssh``` terminal to give you access to remote machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. After launching is completed, scroll down and click “View Instance” to view information about your instance including its public DNS. This will be used along with the key pair to connect to your instance using the command below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ssh -i <path to .pem file> ec2-user@<public dns of your ec2 instance>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have connected to the machine via SSH, let's first check if we have the required Python interpreter in the machine. Check if python3 exists, by typing `python3` on the shell. If Python3 exists, you will see the python shell. If not, install Python3 with the following command:\n",
    "\n",
    "    sudo yum update\n",
    "    sudo yum install python36\n",
    "\n",
    "Next, let's install the dependencies that we are going to use in this case. For installing python dependencies, we need pip. Let's install pip with the below command\n",
    "\n",
    "    sudo yum install python36-pip\n",
    "    \n",
    "\n",
    "The above command will install pip3, which installs the dependencies for the Python3. Using this, we are going to install the dependent python libraries that we are going to use for today's case.\n",
    "\n",
    "    pip-3.6 install --user requests pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering with the OpenWeatherMap API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to register with the OpenWeatherMap API, visit - https://home.openweathermap.org/users/sign_up and Sign up. Once you register on the site and verify your email address, you can login to the site and see the API Key in the `API Keys` tab, in the home page after login."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data from OpenWeatherMap API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a Python script to fetch the weather data from Open WeatherMap API. The API documentation for Open WeatherMap can be found here - https://openweathermap.org/api/hourly-forecast. We will be using this forecast endpoint to fetch the current weather conditions of New York. When calling this endpoint, we would have to provide the latitude and longitude of the location for which we need the weather status. You will need to pass the coordinates of New York. Which are - `40.7128` and `-74.0060`.\n",
    "\n",
    "In your home folder, let's create a file named `fetch_weather_data.py` which will fetch the weather data and store it in a json file locally. The json file should be stored in the following folder structure - `openweathermap_data/raw_data/`. The file name should be of the following format - `weather_{datetime}.json`. Where datetime is the time for which the data is fetched. It can be found inside the `currently` key in the response.\n",
    "\n",
    "The file should also be written to `openweathermap_data/raw_data/weather.json`, for the second script to be able to easily find the latest file to read and execute.\n",
    "\n",
    "The sample of the file can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your ssh terminal, create and open a new file with the following command:\n",
    "\n",
    "    nano fetch_weather_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "OPENWEATHERMAP_API_KEY = '6be5b5fb9384186d26fc8180512ba400' # replace with '<YOUR-OPENWEATHERMAP_API-KEY>'\n",
    "WEATHER_LOCATION_LATITUDE = '40.7128'\n",
    "WEATHER_LOCATION_LONGITUDE = '-74.0060'\n",
    "\n",
    "# First, check if the data folder is present. If not, create it\n",
    "data_folder = 'openweathermap_data/raw_data'\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    \n",
    "# Generate the URL\n",
    "url = 'https://api.openweathermap.org/data/2.5/onecall?lat={0}&lon={1}&appid={2}'.format(\n",
    "    WEATHER_LOCATION_LATITUDE, WEATHER_LOCATION_LONGITUDE, OPENWEATHERMAP_API_KEY)\n",
    "response = requests.get(url)\n",
    "weather_data = response.json()\n",
    "current_datetime = datetime.datetime.fromtimestamp(weather_data['current']['dt']).strftime('%Y_%m_%d_%H_%M')\n",
    "filename = os.path.join(data_folder, 'weather_{0}.json'.format(current_datetime))\n",
    "with open(filename, 'w+') as f:\n",
    "    f.write(json.dumps(weather_data))\n",
    "    \n",
    "latest_filename = os.path.join(data_folder, 'weather.json')\n",
    "with open(latest_filename, 'w+') as f:\n",
    "    f.write(json.dumps(weather_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and visualizing the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next section, we will be parsing the raw json data to convert it to a pandas dataframe, perform some operations on it. After that, we will be writing the csv to a local file and then perform operations on it. We will be:\n",
    "\n",
    "- Calculating the predicted max, min and average temperature for the next 48 hours\n",
    "- Calculate the predicted max, min and average wind speed for the next 48 hours\n",
    "- Draw a line graph on how the temperature would vary in the next 48 hours\n",
    "- Draw a line graph on how the wind speed would vary in the next 48 hours.\n",
    "\n",
    "The output of each section should be stored to a file.\n",
    "\n",
    "For each of the operations, we will be writing functions here and you will have to create a python file in the EC2 instance that calls all these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will create a function that will read the latest json file (with the name `weather.json`), and convert the time from timestamp into a proper datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "current_date_time = None\n",
    "\n",
    "def get_latest_weather_data():\n",
    "    global current_date_time\n",
    "    filename = 'openweathermap_data/raw_data/weather.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data['hourly'])\n",
    "    \n",
    "    # Convert time into a proper datetime object\n",
    "    df['time'] = pd.to_datetime(df['dt'], unit='s')\n",
    "    \n",
    "    # Set the current date time of the data in the global variable. This will be accessed later.\n",
    "    current_date_time = datetime.datetime.fromtimestamp(data['current']['dt']).strftime('%Y_%m_%d_%H_%M')\n",
    "    return df\n",
    "\n",
    "df = get_latest_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write parsed dataframe to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data parsing done, let's write the dataframe to a csv file. Similar to how there is a folder for the raw_data, we need to create a folder for the output data. We also need to create a folder inside output data for each run, as each run creates multiple output files.\n",
    "\n",
    "Once the folders are created, write the dataframe to a file called `output.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def write_csv_file(dataframe):\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        \n",
    "    filename = os.path.join(folder_name, 'output.csv')\n",
    "    dataframe.to_csv(filename, index=False)\n",
    "    \n",
    "write_csv_file(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Min and Average data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as per the requirements, is to calculate the max, min and average values of temperature and windspeed. We need to write those values to a different csv file. Let's write a function that calculates and returns the max, min and average of the temperature column. Store the returned value in a list, as we want to save the stats for both temperature and windspeed in the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_temperature_stats(dataframe):\n",
    "    temperature_data = {'stat': 'temp'}\n",
    "    temperature_data['max'] = dataframe['temp'].max()\n",
    "    temperature_data['min'] = dataframe['temp'].min()\n",
    "    temperature_data['average'] = dataframe['temp'].mean()\n",
    "    return temperature_data\n",
    "\n",
    "stats = []\n",
    "stats.append(calculate_temperature_stats(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to calculate the min, max and average stats of windspeed similar to temperature. Append the stats to the same list, and write that to a csv file named `stats.csv` in the same folder output file was written to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next operation is to plot the variations of temperature across time. We'll use matplotlib to plot the graph and write it to a file in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_temperature(dataframe):\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    filename = os.path.join(folder_name, 'temperature.png')\n",
    "    df.plot.line(x='time', y='temp')\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "plot_temperature(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how the temperature variations were plotted and save to a file, plot the windspeed variations and write the output to `windspeed.png` in the output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the functions into a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been performing the operations one after the other in the above steps. Create a file called `process_weather_data.py` in your EC2 instance that contains all the functions we created so far. The file should look something like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "current_date_time = None\n",
    "\n",
    "\n",
    "def get_latest_weather_data():\n",
    "    global current_date_time\n",
    "    filename = 'openweathermap_data/raw_data/weather.json'\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    df = pd.DataFrame(data['hourly'])\n",
    "    \n",
    "    # Convert time into a proper datetime object\n",
    "    df['time'] = pd.to_datetime(df['dt'], unit='s')\n",
    "    \n",
    "    # Set the current date time of the data in the global variable. This will be accessed later.\n",
    "    current_date_time = datetime.datetime.fromtimestamp(data['current']['dt']).strftime('%Y_%m_%d_%H_%M')\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_csv_file(dataframe):\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        \n",
    "    filename = os.path.join(folder_name, 'output.csv')\n",
    "    dataframe.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "def calculate_temperature_stats(dataframe):\n",
    "    temperature_data = {'stat': 'temp'}\n",
    "    temperature_data['max'] = dataframe['temp'].max()\n",
    "    temperature_data['min'] = dataframe['temp'].min()\n",
    "    temperature_data['average'] = dataframe['temp'].mean()\n",
    "    return temperature_data\n",
    "\n",
    "\n",
    "def calculate_windspeed_stats(dataframe):\n",
    "    temperature_data = {'stat': 'wind_speed'}\n",
    "    temperature_data['max'] = dataframe['wind_speed'].max()\n",
    "    temperature_data['min'] = dataframe['wind_speed'].min()\n",
    "    temperature_data['average'] = dataframe['wind_speed'].mean()\n",
    "    return temperature_data\n",
    "\n",
    "\n",
    "def plot_temperature(dataframe):\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    filename = os.path.join(folder_name, 'temperature.png')\n",
    "    df.plot.line(x='time', y='temp')\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "\n",
    "\n",
    "def plot_windspeed(dataframe):\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    filename = os.path.join(folder_name, 'wind_speed.png')\n",
    "    df.plot.line(x='time', y='wind_speed')\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "    \n",
    "if True:  #__name__ == '__main__':\n",
    "    df = get_latest_weather_data()\n",
    "    write_csv_file(df)\n",
    "    stats = []\n",
    "    stats.append(calculate_temperature_stats(df))\n",
    "    stats.append(calculate_windspeed_stats(df))\n",
    "\n",
    "    # Write the stats to a csv file\n",
    "    folder_name = 'openweathermap_data/output_data/{0}'.format(current_date_time)\n",
    "    filename = os.path.join(folder_name, 'output.csv')\n",
    "    pd.DataFrame(stats).to_csv(filename, index=False)\n",
    "    plot_temperature(df)\n",
    "    plot_windspeed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bash script and setup cronjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both the Python files ready, create a new file called `process_weather_data.sh` and call both the Python files one after the other. The created file should have these lines:\n",
    "\n",
    "    cd ~\n",
    "    python36 fetch_weather_data.py\n",
    "    python36 process_weather_data.py\n",
    "    \n",
    "    \n",
    "After the file is created, convert the file to an executable format:\n",
    "\n",
    "    chmod +x process_weather_data.sh\n",
    "    \n",
    "Now this file is executable and can be run as a bash script. Let's test it by removing the `openweathermap_data` folder and running the file to make sure everything works fine.\n",
    "\n",
    "    rm -rf openweathermap_data\n",
    "    ./process_weather_data.sh\n",
    "    \n",
    "Make sure the openweathermap_data folder is created with raw_data and output_data folders inside it.\n",
    "\n",
    "If the file works as expected, let's create a cronjob that would execute the file every hour, so that the data gets stored in the instance every hour. Some basics on cron jobs can be found here - https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/. In order to edit the cron jobs file, type the following command:\n",
    "\n",
    "    crontab -e\n",
    "    \n",
    "This will open a file that shows the list of cronjobs configured. Add the following line to the end of the file:\n",
    "\n",
    "    0 * * * * /home/ubuntu/process_weather_data.sh\n",
    "    \n",
    "Once the line is added, you can save and exit out of the file. We have now successfully configured the system to execute both the python scripts every hour, and the timestamped file and folder names will make sure we get access to hourly data even long after they are fetched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we learned how to use requests library to fetch data from API, store it in a file, manipulate it to get some proper information out of it. We also learned about cronjobs and how they can be useful to schedule commands to be executed at specific time periods. \n",
    "\n",
    "We had to make sure the data fetched every time is properly timestamped, as the data should not be overwritten when the process runs next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we created a basic automation script and hosted it in the cloud using an Amazon AWS ```EC2``` instance. We know know how to:\n",
    "    \n",
    "1. Configure and launch an EC2 instance\n",
    "2. Connect to the instance using SSH\n",
    "3. Edit files remotely\n",
    "4. Schedule routine tasks using ```crontab```\n",
    "    \n",
    "In the future, we will learn to augment ```EC2``` with storage provided by AWS's ```RDS```. Your role as a data professional should be to familiarize yourself with the different cloud services available at the major players and know when to use a service that is best suited for your use case. In this case, as we only had a simple computational task, we opted for a small (and free) computation cloud service provided by Amazon to complete the task.\n",
    "\n",
    "As we only skimmed the most basic configuration options in Amazon EC2, we recommend going back and investigating the different options available to you in Amazon ```EC2```. Of particular interest to you should be the different images available as some are specialized and come with machine learning libraries pre-installed. You should also familiarize yourself with [pricing](https://aws.amazon.com/ec2/pricing/on-demand/) for on-demand resources. And remember, turn off your instance if it's not doing anything! You can find instructions for terminating your EC2 instances [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
